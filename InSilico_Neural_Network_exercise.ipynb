{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In todays exercise you will make a simple feedforward neural network that can replicate the *in silico* color mixer. You will be given quite a lot of code and only have to fill in a few blanks for this notebook to work. However, the purpose of this exercise is not only getting a NN that works but for you to gain some insight into neural networks and experiment with varying various aspects. You can vary \n",
    "\n",
    "* The noise level in the SilicoColorMixer used to generate data\n",
    "* The input data\n",
    "  * Amount of data\n",
    "  * Different methods to pretreat data\n",
    "  * Combine data with different pretreatment in one data set\n",
    "* The Neural Network architecture\n",
    "  * Number of hidden layers\n",
    "  * Size of hidden layers\n",
    "  * Loss function\n",
    "* Evaluation method\n",
    "* Any other interesting parameter/feature that you might come up with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by getting the MLPRegressor from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "except:\n",
    "    !pip3 install scikit-learn --user --upgrade\n",
    "    from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in other packages that you (might) need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_pie_charts import make_piechart_plot\n",
    "from silico_color_mixer import SilicoColorMixer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate som input data. You can generate data in various ways. You can specify color inputs that you would really like to be in the data set or do as done below - generate some random data. We generate a 400 by 4 array with random numbers between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(np.random.rand(400, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As nice trick when dealing with NN is to normalize your inputs. It is even more true in this case where our true model, the `SilicoColorMixer`, only cares about the ratio of inputs as it normalizes within. Below is a function that normalizes a color list. The `try - except` clause makes the function less sensitive to the format of the input data thus gives some flexibility during other data pretreatments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(color_list):\n",
    "    sum_list = sum(color_list)\n",
    "    try:\n",
    "        norm_list = [1. / sum_list[0] * i for i in color_list]\n",
    "    except:\n",
    "        norm_list = [1. / sum_list * i for i in color_list]\n",
    "    return norm_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pretreat the data. To avoid all data being a mix of all colors, you could remove one color from each data point at random as done below. You can do this two times if you like or come up with your own way of pretreating data to get a different training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, line in enumerate(x):\n",
    "    line[np.random.randint(0,4)] = 0\n",
    "    x[idx] = normalize(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to combine two lists which have undergone different data treatment you can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array(np.random.rand(100, 4))\n",
    "xz = np.concatenate((x, z))\n",
    "print(len(xz)) # The length of the new array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make a list with the colors that are generated by the inputs. Our training data consist of input and corresponding output. What type of learning is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbs = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially try using a color mixer without noise. Once you get the grasp of it, go back to here and add some noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_mixer = SilicoColorMixer(noise=False)\n",
    "# data_generator_mixer = SilicoColorMixer(noise={'colors': 1, 'volume': 0.02, 'measurement': 2},)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the output.\n",
    "\n",
    "Note: We use a lot of `for` loops to the point where professional programmers will likely cry out in agony, because they are slow compared to smarter ways of obtaining the same operations. We use them because they are easy to write, read, and understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rand_data in x:\n",
    "    rgbs.append(data_generator_mixer.run_cuvette(rand_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rgbs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to visualize the colors in your training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(rgbs)\n",
    "plt.axis('off')\n",
    "data_array = np.asarray(rgbs).reshape(20, 20, 3)  # Change this as needed, 20 x 20 = 400\n",
    "plt.imshow(np.asarray(data_array, dtype=np.uint8))\n",
    "plt.imshow(np.array(data_array, dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if you can verify that you have a good distribution of inputs.\n",
    "\n",
    "Change the format of the output from tuple to list, which is what you need to give the neural network (Programmers, look away!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbs_list = []\n",
    "for color in rgbs:\n",
    "    rgbs_list.append(list(color))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to train a neural network. We are using the \"Regressor\" because we want numerical input to return numerical output. Seek out [the online documentation of MLPRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html). Figure out what the different keywords mean and what other keywords can be specified.\n",
    "\n",
    "Below, a neural network is initialized and then trained to your data with the `fit` method. If training takes more than 15 seconds, you have overdone it in some way or another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl = MLPRegressor(solver='lbfgs', alpha=1e-5,\n",
    "                   hidden_layer_sizes=(10,10, 3), random_state=1, max_iter=4000)\n",
    "\n",
    "mpl.fit(x,rgbs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, test how well the neural network performs. Use a noiseless color mixer for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mixer = SilicoColorMixer(noise=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare point by point. This can be good sometimes if you have certain points that you know your are particularly interested in. You could also have included such points in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = [0.25, 0.25, 0., 0.5]\n",
    "print(mpl.predict([point]))\n",
    "print(test_mixer.run_cuvette(point))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do the performance evaluation on a larger data set and more systematically. Generate some data the way you did before. Note, that when you generate data the same way you may inadvertently sample the same subset of data that your used to train the NN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(np.random.rand(100, 4))\n",
    "for idx, line in enumerate(x_test):\n",
    "    line[np.random.randint(0,4)] = 0\n",
    "    x_test[idx] = normalize(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good way to quantify the difference between the test_mixer and the NN is to use your good old \"score\" function. Copy it in the cell below. Note that the output from the NN will be a list. Your \"score\" function might treat lists and tuples the same (`input_color1[0]` does not care whether `input_color1` is a list or a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your \"score\" function here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the difference scores for the points in the test set and add them to a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for x_test_point in x_test:\n",
    "    nn = mpl.predict([x_test_point])\n",
    "    silico = test_mixer.run_cuvette(x_test_point)  \n",
    "    scores.append(your_score_function(nn[0], silico))  # Replace with your score function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reduce this to a few interesting numbers by calculating statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean: \",np.mean(scores),\" Standard deviation: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to rerun the evaluation without changing code but using a new set of random test data. How much does it change? What if you use new training data and retrain the NN. How much do the numbers change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rinse and repeat. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a good understanding and have examined how varying different parameters change the result, you are done with the exercise. Take a moment to appreciate yourself for your efforts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
